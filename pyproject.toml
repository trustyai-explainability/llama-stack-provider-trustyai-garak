[project]
name = "llama-stack-provider-trustyai-garak"
version = "0.1.5"
description = "Out-Of-Tree Llama Stack provider for Garak Red-teaming"
readme = "README.md"
requires-python = ">=3.12"
license = "Apache-2.0"
authors = [
    {name = "Sai Chandra Pandraju", email = "saichandrapandraju@gmail.com"},
    {name = "TrustyAI Team"}
]
keywords = ["llama-stack", "garak", "red-teaming", "security", "ai-safety"]
dependencies = [
    "llama-stack>=0.3.0",
    "greenlet==3.2.4", # because inline/files/localfs errors saying greenlet not found
    "httpx[http2]==0.28.1",
    "garak==0.12.0",
    "setuptools-scm==9.2.0", # to build wavedrom
]

[project.urls]
homepage = "https://github.com/trustyai-explainability/llama-stack-provider-trustyai-garak"
repository = "https://github.com/trustyai-explainability/llama-stack-provider-trustyai-garak"

[build-system]
requires = ["setuptools==80.9.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["src"]

[project.optional-dependencies]
remote = ["kfp==2.14.3", "kfp-kubernetes==2.14.3", "kfp-server-api==2.14.3", "boto3==1.40.27"]
dev = ["pytest", "pytest-cov",  "pytest-asyncio", "black", "isort"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_paths = ["src"]
addopts = "-v"
